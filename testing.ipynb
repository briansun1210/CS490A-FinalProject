{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "import scispacy\n",
    "import spacy\n",
    "import sklearn\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group_3' 'group_2' 'group_1']\n",
      "0       3\n",
      "1       2\n",
      "2       2\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4961    3\n",
      "4962    3\n",
      "4963    3\n",
      "4964    3\n",
      "4965    3\n",
      "Name: medical_specialty, Length: 4966, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_t = pd.read_csv(\"mtsamples_t2.csv\")\n",
    "\n",
    "temp = [i for i in data_t.index if pd.isna(data_t[\"transcription\"][i])]\n",
    "data_t = data_t.drop(temp)\n",
    "data_t = data_t.reset_index(drop=True)\n",
    "print(data_t[\"medical_specialty\"].unique())\n",
    "\n",
    "d = {'group_1': 1, 'group_2': 2, 'group_3': 3}\n",
    "label = data_t['medical_specialty'].map(d, na_action='ignore')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using C:\\Users\\Admin\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "\n",
    "\n",
    "# Loading tokenizer from the bert layer\n",
    "PRE_TRAINED_MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string  \n",
    "punct = set(string.punctuation)\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "med7 = spacy.load(\"en_core_med7_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_doc(text):\n",
    "    bow = defaultdict(float)\n",
    "    temp = []\n",
    "    doc = nlp(text)\n",
    "    doc = doc.ents\n",
    "    lowered_tokens = map(lambda t: str(t).lower(), doc)\n",
    "\n",
    "    for token in lowered_tokens:\n",
    "        temp.append(token)\n",
    "#     temp = getNGrams(temp,5)\n",
    "    temp = \" \".join(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thai\n",
    "from random import sample, randrange \n",
    "import copy\n",
    "g1 = list(data_t[data_t[\"medical_specialty\"] == \"group_1\"].index.values)\n",
    "g2 = list(data_t[data_t[\"medical_specialty\"] == \"group_2\"].index.values)\n",
    "g3 = list(data_t[data_t[\"medical_specialty\"] == \"group_3\"].index.values)\n",
    "g1_temp = copy.deepcopy(g1)\n",
    "g2_temp = copy.deepcopy(g2)\n",
    "g3_temp = copy.deepcopy(g3)\n",
    "\n",
    "t1 = [g1_temp.pop(randrange(len(g1_temp))) for _ in range(1220)]\n",
    "t2 = [g2_temp.pop(randrange(len(g2_temp))) for _ in range(1220)]\n",
    "t3 = [g3_temp.pop(randrange(len(g3_temp))) for _ in range(1220)]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "train_index = t1+t2+t3\n",
    "test_index = g1_temp + g2_temp + g3_temp\n",
    "\n",
    "X_train, X_test = data_t['transcription'][train_index], data_t['transcription'][test_index]\n",
    "y_train, y_test = data_t['medical_specialty'][train_index], data_t['medical_specialty'][test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [tokenize_doc(x) for x in X_train]\n",
    "X_test = [tokenize_doc(x) for x in X_test]\n",
    "# data['transcription'].apply((lambda x: tokenize_doc(x) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'group_1': 1, 'group_2': 2, 'group_3': 3}\n",
    "y_train = y_train.map(d, na_action='ignore')\n",
    "y_test = y_test.map(d, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discharge diagnoses:,1 acute cerebrovascular accident/left basal ganglia deep white matter left parietal lobe.,2 hypertension.,3 urinary tract infection.,4 portable chest impression atherosclerotic change aortic knob.,2 chest portable impression mild tortuosity thoracic aorta maybe hypertension right lateral costophrenic angle swallowing study normal swallowing study minimal penetration thin liquids.,4 head ct air-fluid level right maxillary sinus acute sinusitis 1.8-cm oval low density mass dependent portion left maxillary sinus retention mucoparietal cell right maxillary sinus ethmoid sinuses.,4 iv ct scan head neck brain changes consistent with infarct right basal ganglia deep white matter left parietal lobe diffuse smooth narrowing left middle cerebral artery congenital abnormality clinical correlation necessary.,6 echocardiogram bubble study impression normal left ventricular systolic function left ventricular ejection fraction mild concentric left ventricular hypertrophy left atrial size negative bubble study.,7 carotid duplex ultrasound grade 1 carotid stenosis right evidence carotid stenosis left.,history physical white male history hypertension years untreated patient woke sudden onset right-sided weakness arm hand leg foot right facial droop right hand numbness dorsal side left face numbness slurred speech patient ems emergency room patient night aspirin er ct brain changes ct machine ahead brain neck infarct right basal ganglia deep white matter left parietal lobe smooth left middle cerebral patient micu.,hospital per problem list:,1 acute cerebrovascular accident patient tissue plasminogen activator neurology dr. s. she agrees treatment patient patient aspirin zocor day fasting blood lipids triglycerides hdl cholesterol 22 ldl cholesterol 107 dr. farber treat risk factors blood pressure weeks stroke patient p.r.n labetalol systolic blood pressure diastolic blood pressure patient's blood pressure stable blood pressure medications right leg improving increased muscle strength right upper extremity slurred speech patient pt ot speech therapy day hospitalization patient transferred day admission stable neurologic exam secondary stroke dr. f. echocardiogram normal left ventricular function bubble study negative carotid ultrasound mild stenosis right side ekg changes patient siskin rehabilitation hospital secondary stroke prevention blood pressure treatment systolic diastolic week stroke discharge neurologic exam right facial palsy eye below right upper extremity right leg improved slurred speech.,2 hypertension item blood pressure stable urinary tract infection patient urinalysis leukocyte esterase blood red blood cells white blood cells bacteria patient cipro finish days antibiotic treatment uti urine culture sensitivity negative.,4 hypercholesterolemia patient zocor daily goal ldl patient ldl hdl triglycerides cholesterol discharge stable.,activity tolerated.,diet low-fat low-salt cardiac diet.,discharge instructions:,1 medications regularly.,2 pt ot speech therapist evaluate treat siskin rehab hospital.,3 days medications:,1 tablet days.,2 tablet docusate sodium zocor tablet bedtime.,5 patient rehabilitation hospital discharged there.,2 patient clinic appointment patient primary care physician insurance\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tokenized = pd.Series(tokenized)\n",
    "# tokenized = tokenized.apply((lambda x: tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))))\n",
    "tokenized_train = [tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))[0:510] for x in X_train]\n",
    "tokenized_test = [tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))[0:510] for x in X_test]\n",
    "# # Reshaping the array:\n",
    "# max_len = 0\n",
    "# for i in tokenized:\n",
    "#     if len(i) > max_len:\n",
    "#         max_len = len(i)\n",
    "# print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(tokeniz_s, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discharge diagnoses:,1 acute cerebrovascular accident/left basal ganglia deep white matter left parietal lobe.,2 hypertension.,3 urinary tract infection.,4 portable chest impression atherosclerotic change aortic knob.,2 chest portable impression mild tortuosity thoracic aorta maybe hypertension right lateral costophrenic angle swallowing study normal swallowing study minimal penetration thin liquids.,4 head ct air-fluid level right maxillary sinus acute sinusitis 1.8-cm oval low density mass dependent portion left maxillary sinus retention mucoparietal cell right maxillary sinus ethmoid sinuses.,4 iv ct scan head neck brain changes consistent with infarct right basal ganglia deep white matter left parietal lobe diffuse smooth narrowing left middle cerebral artery congenital abnormality clinical correlation necessary.,6 echocardiogram bubble study impression normal left ventricular systolic function left ventricular ejection fraction mild concentric left ventricular hypertrophy left atrial size negative bubble study.,7 carotid duplex ultrasound grade 1 carotid stenosis right evidence carotid stenosis left.,history physical white male history hypertension years untreated patient woke sudden onset right-sided weakness arm hand leg foot right facial droop right hand numbness dorsal side left face numbness slurred speech patient ems emergency room patient night aspirin er ct brain changes ct machine ahead brain neck infarct right basal ganglia deep white matter left parietal lobe smooth left middle cerebral patient micu.,hospital per problem list:,1 acute cerebrovascular accident patient tissue plasminogen activator neurology dr. s. she agrees treatment patient patient aspirin zocor day fasting blood lipids triglycerides hdl cholesterol 22 ldl cholesterol 107 dr. farber treat risk factors blood pressure weeks stroke patient p.r.n labetalol systolic blood pressure diastolic blood pressure patient's blood pressure stable blood pressure medications right leg improving increased muscle strength right upper extremity slurred speech patient pt ot speech therapy day hospitalization patient transferred day admission stable neurologic exam secondary stroke dr. f. echocardiogram normal left ventricular function bubble study negative carotid ultrasound mild stenosis right side ekg changes patient siskin rehabilitation hospital secondary stroke prevention blood pressure treatment systolic diastolic week stroke discharge neurologic exam right facial palsy eye below right upper extremity right leg improved slurred speech.,2 hypertension item blood pressure stable urinary tract infection patient urinalysis leukocyte esterase blood red blood cells white blood cells bacteria patient cipro finish days antibiotic treatment uti urine culture sensitivity negative.,4 hypercholesterolemia patient zocor daily goal ldl patient ldl hdl triglycerides cholesterol discharge stable.,activity tolerated.,diet low-fat low-salt cardiac diet.,discharge instructions:,1 medications regularly.,2 pt ot speech therapist evaluate treat siskin rehab hospital.,3 days medications:,1 tablet days.,2 tablet docusate sodium zocor tablet bedtime.,5 patient rehabilitation hospital discharged there.,2 patient clinic appointment patient primary care physician insurance\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input = bert_encode(X_train, tokenizer, max_len= MAX_LEN)\n",
    "# encode  test set \n",
    "test_input = bert_encode(X_test, tokenizer, max_len= MAX_LEN )\n",
    "train_labels = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import  Input\n",
    "input_word_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_mask\")\n",
    "segment_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"segment_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])  \n",
    "clf_output = sequence_output[:, 0, :]\n",
    "out = Dense(1, activation='sigmoid')(clf_output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 510)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 510)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 510)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 768)]        0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            769         tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# intilize model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "92/92 [==============================] - 3942s 43s/step - loss: 0.0317 - accuracy: 0.4167 - val_loss: -0.7555 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "92/92 [==============================] - 3896s 42s/step - loss: -0.0013 - accuracy: 0.4167 - val_loss: -0.8260 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1370171c4c52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_input)\n",
    "preds = test_pred.round().astype(int)\n",
    "# print(metrics.classification_report(preds, y_test.to_numpy(), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(metrics.classification_report(preds, y_test.to_numpy(), digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
